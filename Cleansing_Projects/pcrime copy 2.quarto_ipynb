{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Portland Crime Analysis\"\n",
        "subtitle: \"Data Science Portfolio\"\n",
        "author: \"Tucker Trost\"\n",
        "format:\n",
        "  html:\n",
        "    self-contained: true\n",
        "    page-layout: full\n",
        "    title-block-banner: true\n",
        "    toc: true\n",
        "    toc-depth: 3\n",
        "    toc-location: body\n",
        "    number-sections: false\n",
        "    html-math-method: katex\n",
        "    code-fold: true\n",
        "    code-summary: \"Show the code\"\n",
        "    code-overflow: wrap\n",
        "    code-copy: hover\n",
        "    code-tools:\n",
        "        source: false\n",
        "        toggle: true\n",
        "        caption: See code\n",
        "execute: \n",
        "  warning: false\n",
        "    \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Portland Crime Analysis\n",
        "\n",
        "## Elevator pitch\n",
        "\n",
        "_This project involves cleaning and exploring crime data from Portland, Oregon (2016-2023). After addressing missing data and unnecessary columns, we uncovered key trends in offense types, report times, and their relationship to neighborhood, day, and time. These insights help provide a clearer picture of crime patterns in the city._\n",
        "\n",
        "### Data Source\n",
        "_The dateset that I am using was accessed directly from [Portland Police Bureau's Open Data initiative](https://www.portland.gov/police/open-data/crime-statistics); compiled from 2015-2023. This dataset is being used under this [license](https://creativecommons.org/publicdomain/zero/1.0/)._\n",
        "\n",
        "### Data Dictionary\n",
        "\n",
        "_**Address:** Address of reported incident at the 100 block level (e.g.: 1111 SW 2nd Ave would be 1100 Block SW 2nd Ave)._\n",
        "\n",
        "_**Case Number:** The case year and number for the reported incident (YY-######)._\n",
        "\n",
        "_**Crime Against:** Crime against category (Person, Property, or Society)._\n",
        "\n",
        "_**Neighborhood:** Neighborhood where incident occurred. If the neighborhood name is missing, the incident occurred outside of the boundaries of the Portland neighborhoods or at a location that could not be assigned to a specific address in the system. (e.g., Portland, near Washington Park, on the streetcar, etc.)._\n",
        "\n",
        "_**Occur Date:** Date the incident occurred. The exact occur date is sometimes unknown. In most situations, the first possible date the crime could have occurred is used as the occur date. (For example, victims return home from a week-long vacation to find their home burglarized. The burglary could have occurred at any point during the week. The first date of their vacation would be listed as the occur date.)_\n",
        "\n",
        "_**Occur Time**: Time the incident occurred. The exact occur time is sometimes unknown. In most situations, the first possible time the crime could have occurred is used as the occur time. The time is reported in the 24-hour clock format, with the first two digits representing hour (ranges from 00 to 23) and the second two digits representing minutes (ranges from 00 to 59)._\n",
        "\n",
        "_**Offense Category:** Category of offense (for example, Assault Offenses)._\n",
        "\n",
        "_**Offense Type:** Type of offense (for example, Aggravated Assault)Note: The statistic for Homicide Offenses has been updated in the Group A Crimes report to align with the 2019 FBI NIBRS definitions. The statistic for Homicide Offenses includes (09A) Murder & Non-negligent Manslaughter and (09B) Negligent Manslaughter. As of January 1, 2019, the FBI expanded the definition of negligent manslaughter to include traffic fatalities that result in an arrest for driving under the influence, distracted driving, or reckless driving. **The change in definition impacts the 2019 homicide offenses statistic and the comparability of 2019 homicide statistics to prior year.**_\n",
        "\n",
        "_**Open Data Lat/Lon:** Generalized Latitude / Longitude of the reported incident. For offenses that occurred at a specific address, the point is mapped to the block's midpoint. Offenses that occurred at an intersection is mapped to the intersection centroid._\n",
        "\n",
        "_**Open Data X/Y:** Generalized XY point of the reported incident. For offenses that occurred at a specific address, the point is mapped to the block's midpoint. Offenses that occurred at an intersection is mapped to the intersection centroid. To protect the identity of victims and other privacy concerns, the points of certain case types are not released. XY points use the Oregon State Plane North (3601), NAD83 HARN, US International Feet coordinate system._\n",
        "\n",
        "_**Offense Count:** Number of offenses per incident. Offenses (i.e. this field) are summed for counting purposes._\n"
      ],
      "id": "239730a4"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: libraries\n",
        "#| include: false\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "# from plotnine import *\n",
        "from lets_plot import *\n",
        "LetsPlot.setup_html()\n"
      ],
      "id": "libraries",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare\n"
      ],
      "id": "3bbf3051"
    },
    {
      "cell_type": "code",
      "metadata": {
        "fig.show": true
      },
      "source": [
        "#| label: project-data\n",
        "#| code-summary: Read and format project data\n",
        "# Load in Data\n",
        "pcrime_15 = pd.read_csv('CrimeData-2015.csv')\n",
        "pcrime_16 = pd.read_csv('CrimeData-2016.csv')\n",
        "pcrime_17 = pd.read_csv('CrimeData-2017.csv')\n",
        "pcrime_18 = pd.read_csv('CrimeData-2018.csv')\n",
        "pcrime_19 = pd.read_csv('CrimeData-2019.csv')\n",
        "pcrime_20 = pd.read_csv('CrimeData-2020.csv')\n",
        "pcrime_21 = pd.read_csv('CrimeData-2021.csv')\n",
        "pcrime_22 = pd.read_csv('CrimeData-2022.csv')\n",
        "pcrime_23 = pd.read_csv('CrimeData-2023.csv')\n",
        "\n",
        "# Combine Datasets\n",
        "pcrime_combined = pd.concat([pcrime_15,pcrime_16,pcrime_17,pcrime_18,pcrime_19,pcrime_20,pcrime_21,pcrime_22,pcrime_23], ignore_index=True)\n",
        "pcrime_combined.head()"
      ],
      "id": "project-data",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### What is our goal?\n",
        "_Thinking forward to the analysis that I want to perform with this data, I need to understand what I am looking for when it comes to cleaning. I know that I want to focus my analysis on the distribution of different offense types and categories across the various neighborhoods of Portland. Additionally, I'd like to get insight into the temporal trends that lie within the data. Based on this understanding, I get a better sense of what aspects of the data need to be cleaned._\n"
      ],
      "id": "7dca01fc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: Prepare\n",
        "#| code-summary: Identify Missing Data\n",
        "\n",
        "pcrime_combined.isna().sum()"
      ],
      "id": "Prepare",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initial Observations\n",
        "\n",
        "1. ***A time to report column would be useful***\n",
        "    - *Convert OccurDate and ReportDate to datetime*\n",
        "    - *Create a time to report column*\n",
        "\n",
        "2. ***OpenDataX/Y don't seem necessary for our analysis***\n",
        "    - *Drop OpenDataX and OpenDataY columns*\n",
        "\n",
        "3. ***Address column seems to be redundant as most entries are just a general location***\n",
        "    - *Drop Address column*\n",
        "\n",
        "4. ***Neighborhood averages can be used to find lat/lon***\n",
        "    - *Drop rows with missing Neighborhood and OpenDataLat*\n",
        "    - *Replace all rows with neighborhood but missing Lat/Lon data with average Lat/Lon of their neighborhood*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Data Cleaning\n"
      ],
      "id": "488ef70e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-cleaning\n",
        "#| code-summary: Cleaning\n",
        "\n",
        "# Calculate average Lat/Lon for each neighborhood\n",
        "neighborhood_means = pcrime_combined.groupby('Neighborhood')[['OpenDataLat','OpenDataLon']].transform('mean')\n",
        "\n",
        "# Clean the data\n",
        "pcrime_cleaned = (\n",
        "    pcrime_combined\n",
        "    .drop(columns=['Address', 'OpenDataX', 'OpenDataY'])  # Drop X/Y\n",
        "    .dropna(subset=['OpenDataLat', 'Neighborhood'], how='all')  # Drop missing lat/lon and Neighborhoods\n",
        "    .assign(\n",
        "        OccurDate=pd.to_datetime(pcrime_combined['OccurDate']),  # Convert dates to datetime\n",
        "        week=lambda x: x.OccurDate.dt.isocalendar().week,\n",
        "        year=lambda x: x.OccurDate.dt.year,\n",
        "        month=lambda x: x.OccurDate.dt.month,\n",
        "        dayofmonth=lambda x: x.OccurDate.dt.day,\n",
        "        ReportDate=pd.to_datetime(pcrime_combined['ReportDate']),\n",
        "        ReportDiff=lambda x: (x['ReportDate'] - x['OccurDate']).dt.days,  # Calculate time to report\n",
        "        OpenDataLat=lambda x: x['OpenDataLat'].fillna(neighborhood_means['OpenDataLat']),  # Fill missing Lat/Lon with average Lat/Lon of given neighborhood\n",
        "        OpenDataLon=lambda x: x['OpenDataLon'].fillna(neighborhood_means['OpenDataLon']),\n",
        "        OccurTime=lambda x: x['OccurTime'].astype(str).str.zfill(4),  # Ensure time is in HHMM format\n",
        "        OccurDateTime=lambda x: pd.to_datetime(\n",
        "            x['OccurDate'].dt.strftime('%Y-%m-%d') + ' ' + \n",
        "            x['OccurTime'].str[:2] + ':' + x['OccurTime'].str[2:]), # Combine date and formatted time into datetime\n",
        "        OccurHour=lambda x: x.OccurDateTime.dt.hour,\n",
        "    )\n",
        "    .loc[lambda x: x['OccurDateTime'].dt.year.between(2015, 2023)]  # Filter rows with years within 2015–2023\n",
        ")\n",
        "\n",
        "pcrime_cleaned"
      ],
      "id": "data-cleaning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "md-indent": "  "
      },
      "source": [
        "pcrime_cleaned.info()"
      ],
      "id": "56691325",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "_Now we can check and see how we did filling in our missing data._\n"
      ],
      "id": "1ad0bc79"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-cleaning-2\n",
        "#| code-summary: Check missing data\n",
        "\n",
        "pcrime_cleaned.isna().sum()"
      ],
      "id": "data-cleaning-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Cleaning Thoughts\n",
        "\n",
        "_We have now cleaned our data into a useable state for our analysis. We went from many missing rows from in many columns to only 7881 missing rows in the neighborhood column. Since we have all of the Latitude and Longitude data for each of these missing rows, the missing data will still be useable for our visualizations in Tableau._\n",
        "\n",
        "_Note: Further cleaning of the missing neighborhood rows could be done using a reverse geocoding API, however, that is beyond the scope of this project_\n",
        "\n",
        "## Data Exploration\n",
        "\n",
        "### Thoughts\n",
        "\n",
        "* Temporal Trends\n",
        "    - hour/Day/month/year trends\n",
        "* Crime distributions\n",
        "    - categories/types/crimeagainst\n",
        "    - reportdiff by offense type\n",
        "* Neighborhood\n",
        "    - type/category distributions\n",
        "    - reportdiff by neighborhood\n",
        "    - offense count by neighborhood\n",
        "\n",
        "#### Temporal Trends\n"
      ],
      "id": "c1dd9f71"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-explore-1\n",
        "#| code-summary: year-count\n",
        "\n",
        "from lets_plot import *\n",
        "LetsPlot.setup_html()\n",
        "month_year = (pcrime_cleaned\n",
        "    .assign(\n",
        "        year=pcrime_cleaned['OccurDateTime'].dt.year,\n",
        "        month=pcrime_cleaned['OccurDateTime'].dt.month) \n",
        "    .query('year >= 2019')\\\n",
        "    .groupby(['year', 'month'])\\\n",
        "    ['OffenseCount'].sum()\\\n",
        "    .reset_index()\\\n",
        "    .rename(columns={'OffenseCount': 'count'})\n",
        ")\n",
        "\n",
        "last_month_data = (\n",
        "    month_year.groupby(\"year\")\n",
        "    .apply(lambda df: df[df[\"month\"] == df[\"month\"].max()])\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "month_year[\"year\"] = month_year[\"year\"].astype(str)  # Convert year to string\n",
        "last_month_data[\"year\"] = last_month_data[\"year\"].astype(str)  # Convert for labels\n",
        "\n",
        "month_year_fig = (\n",
        "    ggplot(month_year, aes(x=\"month\", y=\"count\", color=\"year\", group=\"year\")) +\n",
        "    geom_smooth(method='loess', span=0.5,se=False) +\n",
        "    geom_label(data=last_month_data, mapping=aes(y='count',label=\"year\", color=\"year\"),x=12.5, size=7,check_overlap=True)\n",
        " +  # Equivalent of geom_label_repel\n",
        "    labs(title=\"Offense Counts by Month and Year\", x=\"Month\", y=\"Offense Count\") +\n",
        "    theme_minimal() +\n",
        "    theme(legend_position=\"none\") +\n",
        "    scale_x_continuous(breaks=list(range(1, 13)))+\n",
        "    scale_y_continuous(breaks=[4500,4750,5000,5250,5500,5750,6000,6250,6500]))\n",
        "\n",
        "\n",
        "month_year_fig"
      ],
      "id": "data-explore-1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Observations\n",
        "This chart shows that crime levels remained fairly consistent in 2019. In 2020, we see a noticeable drop when the country went into lockdown, followed by a sharp increase as restrictions eased in the summer. Then, in 2021, Portland experienced a significant surge in crime, which remained relatively high until 2023, when it began to stabilize.\n"
      ],
      "id": "7690b128"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-explore-2\n",
        "#| code-summary: Temporal Counts\n",
        "\n",
        "# Month Count\n",
        "\n",
        "month_count = pcrime_cleaned.groupby(pcrime_cleaned['OccurDateTime'].dt.month)['OffenseCount'].sum().reset_index()\n",
        "\n",
        "month_count.rename(columns={month_count.columns[0]: 'Month'}, inplace=True)\n",
        "\n",
        "month_count_fig = ggplot(month_count, aes(x=\"Month\", y=\"OffenseCount\")) + \\\n",
        "    geom_line(color='#2e6f40', size=1.5) + \\\n",
        "    geom_point(color='#2e6f40', size=3) + \\\n",
        "    labs(title='Offense Counts by Month', x='Month', y='Offense Count') + \\\n",
        "    scale_x_continuous(breaks=list(range(1, 13))) + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "# Weekday Count\n",
        "weekday_count = pcrime_cleaned.groupby(pcrime_cleaned['OccurDateTime'].dt.weekday)['OffenseCount'].sum().reset_index()\n",
        "\n",
        "weekday_count.rename(columns={weekday_count.columns[0]: 'Weekday'}, inplace=True)\n",
        "\n",
        "weekday_count_fig = ggplot(weekday_count, aes(x=\"Weekday\", y=\"OffenseCount\")) + \\\n",
        "    geom_line(color='#2e6f40', size=1.5) + \\\n",
        "    geom_point(color='#2e6f40', size=3) + \\\n",
        "    labs(title='Offense Counts by Weekday', x='Weekday', y='Offense Count') + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "# Hour Count\n",
        "hour_count = pcrime_cleaned.groupby(pcrime_cleaned['OccurDateTime'].dt.hour)['OffenseCount'].sum().reset_index()\n",
        "\n",
        "hour_count.rename(columns={hour_count.columns[0]: 'Hour'}, inplace=True)\n",
        "\n",
        "hour_count_fig = ggplot(hour_count, aes(x=\"Hour\", y=\"OffenseCount\")) + \\\n",
        "    geom_line(color='#2e6f40', size=1.5) + \\\n",
        "    geom_point(color='#2e6f40', size=3) + \\\n",
        "    labs(title='Offense Counts by Hour', x='Hour', y='Offense Count') + \\\n",
        "    scale_x_continuous(breaks=list(range(0, 25))) + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "# Create a list of plots to display in a single row\n",
        "temp_plot_list = [\n",
        "    month_count_fig,\n",
        "    weekday_count_fig,\n",
        "    hour_count_fig\n",
        "]\n",
        "\n",
        "# Arrange the plots in a single row\n",
        "temp_plots = gggrid(temp_plot_list, ncol=3) + ggsize(1200, 400)\n",
        "\n",
        "# Show the combined plot\n",
        "temp_plots"
      ],
      "id": "data-explore-2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Observations\n",
        "Crime patterns exhibit distinct temporal trends across months, weekdays, and hours. Monthly data shows that crime tends to slow down during the winter months and gradually rises through the summer and into the rest of the year, potentially influenced by seasonal factors such as weather and increased outdoor activity. Looking at weekly patterns, Friday stands out as the day with the highest number of reported offenses, which aligns with the start of the weekend when more people are out, creating more opportunities for crime. Additionally, crime follows a predictable daily cycle, with certain hours experiencing higher offense counts. These trends suggest that external factors like weather, social behavior, and law enforcement presence may play a role in crime fluctuations, warranting further analysis to uncover deeper insights.\n",
        "\n",
        "#### Crime Distribution Trends\n"
      ],
      "id": "eb3bc5f3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-explore-5\n",
        "#| code-summary: crime_against_count\n",
        "\n",
        "# Crime Against Count\n",
        "crime_against = pcrime_cleaned.groupby('CrimeAgainst',as_index=False)['OffenseCount'].sum()\n",
        "crime_against_fig = ggplot(crime_against, aes(x='CrimeAgainst', y='OffenseCount')) + \\\n",
        "    geom_bar(stat='identity', fill='#2e6f40', color='black') + \\\n",
        "    labs(title='Offense Counts by Crime Type', x='Crime Against', y='Offense Count') + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "# Crime Against Report Time\n",
        "\n",
        "crime_against_report_box = (ggplot(pcrime_cleaned,aes(x='ReportDiff',y='CrimeAgainst'))+\n",
        "  geom_boxplot(outlier_shape = None,fill='#2e6f40', color='black')+\n",
        "  scale_x_log10()+\n",
        "  theme_minimal()+\n",
        "  labs(title = 'Crime Against Report Time Distribution',x= 'Days to Report',y='Crime Against'))\n",
        "\n",
        "crime_against_list = [crime_against_fig,crime_against_report_box]\n",
        "\n",
        "crime_against_plots = gggrid(crime_against_list,ncol=2)+ ggsize(1600, 600)\n",
        "\n",
        "crime_against_plots"
      ],
      "id": "data-explore-5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Observations\n",
        "\n",
        "It’s evident that crimes against property are much more common than other categories. My initial thought is that property crimes may be more frequent because they’re often easier to commit, both physically and morally. Property doesn’t involve direct harm to individuals, which could make it feel less risky or less severe to potential offenders. The differences in report times are also interesting. All crime against types have a median report time of 1 day, however, crime against person has a larger distribution of report times. This also makes sense because many crimes against a person are very sensitive situations that lead to delayed reporting.\n"
      ],
      "id": "49207895"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: data-explore-7\n",
        "#| code-summary: crime_category_count\n",
        "\n",
        "# Crime Category Count\n",
        "crime_cat = pcrime_cleaned.groupby('OffenseCategory',as_index=False)['OffenseCount'].sum().sort_values(by='OffenseCount', ascending=False).head(10)\n",
        "crime_cat_fig = ggplot(crime_cat, aes(x='OffenseCount', y='OffenseCategory')) + \\\n",
        "    geom_bar(stat='identity', fill='#2e6f40', color='black') + \\\n",
        "    labs(title='Offense Counts by Category', x='Offense COunt', y='Offense Category') + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "crime_cat_fig\n",
        "\n",
        "# Crime Type Count\n",
        "crime_type = pcrime_cleaned.groupby('OffenseType',as_index=False)['OffenseCount'].sum().sort_values(by='OffenseCount', ascending=False).head(10)\n",
        "crime_type_fig = ggplot(crime_type, aes(x='OffenseCount', y='OffenseType')) + \\\n",
        "    geom_bar(stat='identity', fill='#2e6f40', color='black') + \\\n",
        "    labs(title='Offense Counts by Type', x='Offense COunt', y='Offense Type') + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "\n",
        "crime_type_fig\n",
        "\n",
        "# Neighborhood Count\n",
        "neigh_count = pcrime_cleaned.groupby('Neighborhood',as_index=False)['OffenseCount'].sum().sort_values(by='OffenseCount', ascending=False).head(10)\n",
        "neigh_count_fig = ggplot(neigh_count,aes(y=neigh_count[\"Neighborhood\"],x=neigh_count[\"OffenseCount\"]))+ \\\n",
        "    geom_bar(stat='identity',fill='#2e6f40', color='black')+ \\\n",
        "    labs(title='Offense Count by Neighborhood', x='Offense Count', y='Neighborhood') + \\\n",
        "    theme_minimal() + \\\n",
        "    theme(\n",
        "        plot_title=element_text(size=16, face='bold'),\n",
        "        axis_title_x=element_text(size=12, face='bold'),\n",
        "        axis_title_y=element_text(size=12, face='bold'),\n",
        "        axis_text_x=element_text(size=10), \n",
        "        axis_text_y=element_text(size=10),\n",
        "        panel_grid_minor=element_blank()\n",
        "    )\n",
        "neigh_count_fig\n",
        "\n",
        "count_list = [crime_cat_fig,crime_type_fig,neigh_count_fig]\n",
        "\n",
        "count_plots = gggrid(count_list, ncol=2) + ggsize(1200, 400)\n",
        "\n",
        "count_plots"
      ],
      "id": "data-explore-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Observations\n",
        "Larceny stands out as the most common offense in Portland, reinforcing the broader trend that property crimes are significantly more prevalent than other crime categories. This may be attributed to the opportunistic nature of larceny—these offenses often require little planning and can happen quickly, unlike more serious crimes that demand time, effort, or emotional involvement. Additionally, neighborhood-level analysis shows that Downtown and Hazelwood experience disproportionately high numbers of reported offenses. While this highlights potential crime hotspots, further context—such as population density, neighborhood size, and visitor traffic—would provide a more accurate understanding of these patterns.\n",
        "\n",
        "## Current Final Observations\n",
        "\n",
        "This project is still a work in progress, and there’s plenty more to explore and visualize to better address some of the questions raised during my analysis. That said, the work completed so far has revealed some fascinating insights into crime patterns in Portland, Oregon. Thank you for taking the time to check out my project—I hope you’ll return to see the updates as it continues to develop!\n",
        "\n",
        "# Machine Learning\n"
      ],
      "id": "3013c55d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def hour_bin(hour):\n",
        "    if 5 <= hour < 12:\n",
        "        return \"Morning\"\n",
        "    elif 12 <= hour < 17:\n",
        "        return \"Afternoon\"\n",
        "    elif 17 <= hour < 21:\n",
        "        return \"Evening\"\n",
        "    else:\n",
        "        return \"Night\"\n",
        "\n",
        "def season_bin(month):\n",
        "    if 3 <= month <= 5:\n",
        "        return \"Spring\"\n",
        "    elif 6 <= month <= 8:\n",
        "        return \"Summer\"\n",
        "    elif 9 <= month <= 11:\n",
        "        return \"Fall\"\n",
        "    else:\n",
        "        return \"Winter\"\n",
        "\n",
        "def weekday_bin(weekday):\n",
        "    if weekday < 5:\n",
        "        return \"Weekday\"\n",
        "    else:\n",
        "        return \"Weekend\"\n",
        "\n",
        "def commute_hours(hour):\n",
        "    if (6 <= hour < 9) or (16 <= hour < 19):\n",
        "        return \"Commuting Hours\"\n",
        "    else:\n",
        "        return \"Non-Commuting Hours\"\n",
        "\n",
        "def temp_bin(temp):\n",
        "    if temp < 32:\n",
        "        return \"Freezing\"\n",
        "    elif 32 <= temp < 50:\n",
        "        return \"Cold\"\n",
        "    elif 50 <= temp < 68:\n",
        "        return \"Cool\"\n",
        "    elif 68 <= temp < 85:\n",
        "        return \"Warm\"\n",
        "    else:\n",
        "        return \"Hot\"\n",
        "\n",
        "def rainy_day(precipitation):\n",
        "    if precipitation > 0:\n",
        "        return \"Rainy Day\"\n",
        "    else:\n",
        "        return \"Not Rainy Day\""
      ],
      "id": "315a7e07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def assign_quadrant(neighborhood):\n",
        "    north = [\n",
        "        \"Arbor Lodge\", \"Boise\", \"Bridgeton\", \"Cathedral Park\", \"East Columbia\", \"Eliot\",\n",
        "        \"Hayden Island\", \"Humboldt\", \"Kenton\", \"Overlook\", \"Piedmont\", \"Portsmouth\",\n",
        "        \"St. Johns\", \"St Johns\", \"University Park\"\n",
        "    ]\n",
        "\n",
        "    northwest = [\n",
        "        \"Arlington Heights\", \"Forest Park\", \"Hillside\", \"Linnton\", \"Northwest Heights\",\n",
        "        \"NW 21st & 23rd Avenue – Nob Hill\", \"Sylvan Highlands\", \"Sylvan-Highlands\",\n",
        "        \"Northwest Industrial\", \"Northwest\"\n",
        "    ]\n",
        "\n",
        "    northeast = [\n",
        "        \"Alameda\", \"Alberta Arts District\", \"Beaumont-Wilshire\", \"North Tabor\", \"Concordia\",\n",
        "        \"Cully\", \"Grant Park\", \"Hollywood\", \"Irvington\", \"King\", \"Madison South\",\n",
        "        \"Rose City Park\", \"Roseway\", \"Sabin\", \"Sullivan’s Gulch\", \"Sullivan's Gulch\",\n",
        "        \"Sumner\", \"Sunderland\", \"Vernon\", \"Woodland Park\", \"Woodlawn\", \"Lloyd\"\n",
        "    ]\n",
        "\n",
        "    central = [\n",
        "        \"China Town/Old Town\", \"Old Town/Chinatown\", \"Downtown\", \"Lloyd Center\",\n",
        "        \"Pearl District\", \"Pearl\", \"South Waterfront\"\n",
        "    ]\n",
        "\n",
        "    southwest = [\n",
        "        \"Arnold Creek\", \"Ashcreek\", \"Bridlemile\", \"Collins View\", \"Crestwood\", \"Far Southwest\",\n",
        "        \"Goose Hollow\", \"Hayhurst\", \"Healy Heights\", \"Hillsdale\", \"Homestead\", \"Maplewood\",\n",
        "        \"Markham\", \"Marshall Park\", \"Multnomah\", \"South Burlingame\", \"Southwest Hills\",\n",
        "        \"West Portland Park\", \"South Portland\"\n",
        "    ]\n",
        "\n",
        "    southeast = [\n",
        "        \"Belmont\", \"Brentwood-Darlington\", \"Brooklyn\", \"Buckman\", \"Buckman East\", \"Buckman West\",\n",
        "        \"Creston-Kenilworth\", \"Eastmoreland\", \"Foster-Powell\", \"Hawthorne\", \"Hosford-Abernethy\",\n",
        "        \"Johnson Creek (aka Ardenwald)\", \"Kerns\", \"Laurelhurst\", \"Montavilla\", \"Mount Scott\",\n",
        "        \"Mount Tabor\", \"Mt Tabor\", \"Mt Scott-Arleta\", \"Reed\", \"Richmond\", \"Sellwood-Moreland\",\n",
        "        \"South Tabor\", \"Sunnyside\", \"Woodstock\", \"Argay\", \"Centennial\", \"Glenfair\", \"Hazelwood\",\n",
        "        \"Lents\", \"Mill Park\", \"Parkrose\", \"Parkrose Heights\", \"Pleasant Valley\",\n",
        "        \"Powellhurst Gilbert\", \"Powellhurst-Gilbert\", \"Russell\", \"Wilkes\", \"Ardenwald\"\n",
        "    ]\n",
        "\n",
        "    if neighborhood in north:\n",
        "        return \"North Portland\"\n",
        "    elif neighborhood in northwest:\n",
        "        return \"Northwest Portland\"\n",
        "    elif neighborhood in northeast:\n",
        "        return \"Northeast Portland\"\n",
        "    elif neighborhood in central:\n",
        "        return \"Central Portland\"\n",
        "    elif neighborhood in southwest:\n",
        "        return \"Southwest Portland\"\n",
        "    elif neighborhood in southeast:\n",
        "        return \"Southeast Portland\"\n",
        "    else:\n",
        "        return \"Unknown Quadrant\"\n"
      ],
      "id": "6c26d4ef",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def fix_neigh(neighborhood):\n",
        "    if neighborhood == 'SUMNER*':\n",
        "        return 'SUMNER'\n",
        "    elif neighborhood == 'NORTHWEST DISTRICT':\n",
        "        return 'NORTHWEST'\n",
        "    elif neighborhood == 'POWELLHURST GILBERT':\n",
        "        return 'POWELLHURST-GILBERT'\n",
        "    elif neighborhood == 'LLOYD DISTRICT':\n",
        "        return 'LLOYD'\n",
        "    elif neighborhood == 'SOUTHWEST HILLS*':\n",
        "        return 'SOUTHWEST HILLS'\n",
        "    elif neighborhood == 'ST. JOHNS':\n",
        "        return 'ST JOHNS'\n",
        "    elif neighborhood == 'OLD TOWN-CHINATOWN':\n",
        "        return 'OLD TOWN/CHINATOWN'\n",
        "    elif neighborhood == 'ARDENWALD-JOHNSON CREEK':\n",
        "        return 'ARDENWALD'\n",
        "    elif neighborhood == 'FOREST PARK*':\n",
        "        return 'FOREST PARK'\n",
        "    elif neighborhood == 'LINNTON*':\n",
        "        return 'LINNTON'\n",
        "    elif neighborhood == 'PLEASANT VALLEY*':\n",
        "        return 'PLEASANT VALLEY'\n",
        "    elif neighborhood == 'BRIDLEMILE*':\n",
        "        return 'BRIDLEMILE'\n",
        "    elif neighborhood == 'SYLVAN HIGHLANDS*':\n",
        "        return 'SYLVAN-HIGHLANDS'\n",
        "    else:\n",
        "        return neighborhood"
      ],
      "id": "528f8801",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pdata = pd.read_csv('pdata.csv')\n",
        "pdata_cleaned = pdata.drop(columns=['Median 2021 home sale price ($)',\n",
        "       'Average 2021 home sale price ($)', 'Homes sold in 2021 (#)',\n",
        "       '1-year median price change 2020-21 (%)',\n",
        "       '5-year median price change 2016-21 (%)', 'Days on market (average)',\n",
        "       'Condo sales among home sales (#)',\n",
        "       'Share of 2021 sales that were condos (%)', 'Short sales',\n",
        "       'Bank-owned sales', 'Average square feet of homes sold',\n",
        "       'Average cost per square foot ($)', 'Average year built of homes sold',\n",
        "       \"Renters' median monthly housing ($)\",'Total newcomers (%)',\n",
        "       'Assault', 'Homicide', 'Sex offenses', 'Arson', 'Robbery', 'Burglary','Larceny',\n",
        "       'Motor vehicle thefts', 'Vandalism', 'Drug/narcotic offenses',\n",
        "       'Violent crimes per 1,000 residents',\n",
        "       'Burglary/larceny/vehicle theft crimes per 1,000 residents',\n",
        "       'Vehicle thefts per square mile'])\\\n",
        "        .assign(\n",
        "            Neighborhood = lambda x: x.Neighborhood.apply(fix_neigh)\n",
        "        ).replace('-', np.nan)"
      ],
      "id": "0993ba9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pdata_cleaned.columns"
      ],
      "id": "a50e3cfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "calendar = USFederalHolidayCalendar()\n",
        "holidays = calendar.holidays(start=pcrime_cleaned.OccurDate.min(), end=pcrime_cleaned.OccurDate.max())"
      ],
      "id": "d86b5984",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pcrime_ml = pcrime_cleaned\\\n",
        "    .groupby(['OccurDate','Neighborhood','OccurHour'])\\\n",
        "    .agg(\n",
        "        total_offenses=('OffenseCount','sum'),\n",
        "        lat=('OpenDataLat','mean'),\n",
        "        lon=('OpenDataLon','mean'))\\\n",
        "    .reset_index()\\\n",
        "    .assign(\n",
        "        OccurDate = lambda x: pd.to_datetime(x.OccurDate),\n",
        "        week=lambda x: x.OccurDate.dt.isocalendar().week,\n",
        "        year=lambda x: x.OccurDate.dt.year,\n",
        "        month=lambda x: x.OccurDate.dt.month,\n",
        "        month_sin=lambda x: np.sin(2 * np.pi * x.month / 12),\n",
        "        month_cos=lambda x: np.cos(2 * np.pi * x.month / 12),\n",
        "        quarter=lambda x: x.OccurDate.dt.quarter,\n",
        "        weekday=lambda x: x.OccurDate.dt.weekday,\n",
        "        weekday_sin=lambda x: np.sin(2 * np.pi * x.weekday / 7),\n",
        "        weekday_cos=lambda x: np.cos(2 * np.pi * x.weekday / 7),\n",
        "        hour_bin=lambda x: x['OccurHour'].apply(hour_bin),\n",
        "        hour_sin=lambda x: np.sin(2 * np.pi * x.OccurHour / 24),\n",
        "        hour_cos=lambda x: np.cos(2 * np.pi * x.OccurHour / 24),\n",
        "        season_bin=lambda x: x['month'].apply(season_bin),\n",
        "        weekday_bin=lambda x: x['weekday'].apply(weekday_bin),\n",
        "        commute_hours=lambda x: x['OccurHour'].apply(commute_hours),\n",
        "        holiday=lambda x: x.OccurDate.isin(holidays),\n",
        "        covid_time = lambda x: (x.OccurDate.dt.date >= dt.date(2020, 3, 15)) & (x.OccurDate.dt.date <= dt.date(2022,6,30)),\n",
        "        quadrant = lambda x: x.Neighborhood.apply(assign_quadrant))\\\n",
        "    .merge(hourly_weather.reset_index(drop=True),on=['OccurDate','OccurHour'],how='left')\\\n",
        "    .merge(daily_weather.reset_index(drop=True),on='OccurDate',how='left')\\\n",
        "    .assign(\n",
        "        temp_bin = lambda x: x.temp_f.apply(temp_bin),\n",
        "        rainy_day= lambda x: x.precipitation.apply(rainy_day),\n",
        "        neigh_upper = lambda x: x.Neighborhood.str.upper()\n",
        "    )\\\n",
        "    .merge(pdata_cleaned,left_on='neigh_upper',right_on='Neighborhood',how='left')\\\n",
        "    .drop(columns=['Neighborhood_y','neigh_upper'])\\\n",
        "    .assign(**{\n",
        "    'Median household income ($)': lambda x: x['Median household income ($)'].astype(float)\n",
        "})\n",
        "\n",
        "pcrime_ml"
      ],
      "id": "54f4aab1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pcrime_ml_daily = pcrime_cleaned\\\n",
        "    .groupby(['OccurDate','Neighborhood'])\\\n",
        "    .agg(\n",
        "        total_offenses=('OffenseCount','sum'),\n",
        "        lat=('OpenDataLat','mean'),\n",
        "        lon=('OpenDataLon','mean'))\\\n",
        "    .reset_index()\\\n",
        "    .assign(\n",
        "        OccurDate = lambda x: pd.to_datetime(x.OccurDate),\n",
        "        week=lambda x: x.OccurDate.dt.isocalendar().week,\n",
        "        year=lambda x: x.OccurDate.dt.year,\n",
        "        month=lambda x: x.OccurDate.dt.month,\n",
        "        month_sin=lambda x: np.sin(2 * np.pi * x.month / 12),\n",
        "        month_cos=lambda x: np.cos(2 * np.pi * x.month / 12),\n",
        "        quarter=lambda x: x.OccurDate.dt.quarter,\n",
        "        weekday=lambda x: x.OccurDate.dt.weekday,\n",
        "        weekday_sin=lambda x: np.sin(2 * np.pi * x.weekday / 7),\n",
        "        weekday_cos=lambda x: np.cos(2 * np.pi * x.weekday / 7),\n",
        "        season_bin=lambda x: x['month'].apply(season_bin),\n",
        "        weekday_bin=lambda x: x['weekday'].apply(weekday_bin),\n",
        "        holiday=lambda x: x.OccurDate.isin(holidays),\n",
        "        covid_time = lambda x: (x.OccurDate.dt.date >= dt.date(2020, 3, 15)) & (x.OccurDate.dt.date <= dt.date(2022,6,30)),\n",
        "        quadrant = lambda x: x.Neighborhood.apply(assign_quadrant))\\\n",
        "    .merge(daily_weather.reset_index(drop=True),on='OccurDate',how='left')\\\n",
        "    .assign(\n",
        "        temp_bin = lambda x: x.max_temp.apply(temp_bin),\n",
        "        neigh_upper = lambda x: x.Neighborhood.str.upper()\n",
        "    )\\\n",
        "    .merge(pdata_cleaned,left_on='neigh_upper',right_on='Neighborhood',how='left')\\\n",
        "    .drop(columns=['Neighborhood_y','neigh_upper'])\\\n",
        "    .assign(**{\n",
        "    'Median household income ($)': lambda x: x['Median household income ($)'].astype(float)\n",
        "})\n",
        "\n",
        "pcrime_ml_daily"
      ],
      "id": "2b180c9c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "daily_weather.head()"
      ],
      "id": "411afe9f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pcrime_ml_daily_lag = pcrime_cleaned\\\n",
        "    .assign(OccurDate=lambda x: pd.to_datetime(x['OccurDate']).dt.date)\\\n",
        "    .groupby(['OccurDate','Neighborhood'])\\\n",
        "    .agg(\n",
        "        total_offenses=('OffenseCount','sum'),\n",
        "        lat=('OpenDataLat','mean'),\n",
        "        lon=('OpenDataLon','mean'))\\\n",
        "    .reset_index()\\\n",
        "    .assign(\n",
        "        OccurDate = lambda x: pd.to_datetime(x.OccurDate),\n",
        "        week=lambda x: x.OccurDate.dt.isocalendar().week,\n",
        "        year=lambda x: x.OccurDate.dt.year,\n",
        "        month=lambda x: x.OccurDate.dt.month,\n",
        "        month_sin=lambda x: np.sin(2 * np.pi * x.month / 12),\n",
        "        month_cos=lambda x: np.cos(2 * np.pi * x.month / 12),\n",
        "        quarter=lambda x: x.OccurDate.dt.quarter,\n",
        "        weekday=lambda x: x.OccurDate.dt.weekday,\n",
        "        weekday_sin=lambda x: np.sin(2 * np.pi * x.weekday / 7),\n",
        "        weekday_cos=lambda x: np.cos(2 * np.pi * x.weekday / 7),\n",
        "        season_bin=lambda x: x['month'].apply(season_bin),\n",
        "        weekday_bin=lambda x: x['weekday'].apply(weekday_bin),\n",
        "        holiday=lambda x: x.OccurDate.isin(holidays),\n",
        "        covid_time = lambda x: (x.OccurDate.dt.date >= dt.date(2020, 3, 15)) & (x.OccurDate.dt.date <= dt.date(2022,6,30)),\n",
        "        quadrant = lambda x: x.Neighborhood.apply(assign_quadrant))\\\n",
        "    .assign(\n",
        "        lag_1 = lambda x: x.groupby('Neighborhood')['total_offenses'].shift(1),\n",
        "        rolling_3 = lambda x: x.groupby('Neighborhood')['total_offenses'].shift(1).transform(lambda s: s.rolling(3).mean())\n",
        "    )\n",
        "\n",
        "pcrime_ml_daily_lag"
      ],
      "id": "121a8a58",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = pcrime_ml_daily_lag.drop(columns=['total_offenses','OccurDate','month','weekday'],axis=1)\n",
        "X = pd.get_dummies(X)\n",
        "y = pcrime_ml_daily_lag['total_offenses']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "xgb = XGBRegressor(\n",
        "    max_depth=10,\n",
        "    learning_rate=0.03,\n",
        "    n_estimators=500,\n",
        "    min_child_weight=25,\n",
        "    subsample=.5,\n",
        "    colsample_bytree=.6,\n",
        "    random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = root_mean_squared_error(y_test,y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "id": "9ac1d921",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = pcrime_ml_daily.drop(columns=['total_offenses','OccurDate','month','weekday'],axis=1)\n",
        "X = pd.get_dummies(X)\n",
        "y = pcrime_ml_daily['total_offenses']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "xgb = XGBRegressor(\n",
        "    max_depth=10,\n",
        "    learning_rate=0.03,\n",
        "    n_estimators=500,\n",
        "    min_child_weight=25,\n",
        "    subsample=.5,\n",
        "    colsample_bytree=.6,\n",
        "    random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = root_mean_squared_error(y_test,y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "id": "dd8ff324",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error"
      ],
      "id": "a52d0de2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "X = pcrime_ml.drop(columns=['total_offenses','OccurDate','OccurHour','month','weekday'],axis=1)\n",
        "X = pd.get_dummies(X)\n",
        "y = pcrime_ml['total_offenses']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a Random Forest Regressor\n",
        "xgb = XGBRegressor(\n",
        "    max_depth=10,\n",
        "    learning_rate=0.03,\n",
        "    n_estimators=500,\n",
        "    min_child_weight=25,\n",
        "    subsample=.5,\n",
        "    colsample_bytree=.6,\n",
        "    random_state=42)\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = root_mean_squared_error(y_test,y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Squared Error: {mse}\")\n",
        "print(f'RMSE: {rmse}')\n",
        "print(f\"R^2 Score: {r2}\")"
      ],
      "id": "921fb958",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'xgb' is your trained XGBRegressor model and 'X' is your feature dataframe\n",
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': xgb.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False).head(20)\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances)  # Top 15 features\n",
        "plt.title('Top Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "id": "ef8ae388",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'xgb' is your trained XGBRegressor model and 'X' is your feature dataframe\n",
        "feature_importances = pd.DataFrame({'Feature': X.columns, 'Importance': xgb.feature_importances_})\n",
        "feature_importances = feature_importances.sort_values(by='Importance', ascending=False).head(20)\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importances)  # Top 15 features\n",
        "plt.title('Top Feature Importances')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()"
      ],
      "id": "eff12912",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lag_check = pcrime_ml_daily_lag[['OccurDate','Neighborhood','total_offenses','lag_1','rolling_3']].sort_values(['Neighborhood','OccurDate'])\n",
        "lag_check"
      ],
      "id": "b9b8082a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dupes = pcrime_ml_daily_lag[pcrime_ml_daily_lag['Neighborhood'] == 'Brentwood-Darlington']\n",
        "dupes = dupes[dupes['OccurDate'] == '2015-01-01']\n",
        "print(dupes['OccurDate'].unique())"
      ],
      "id": "c0e0d45a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/tuckertrost/Library/Python/3.12/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}